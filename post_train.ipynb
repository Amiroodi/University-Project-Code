{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c866f201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\EnvMasoudi\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from going_modular import engine_post_train, utils\n",
    "from going_modular import custom_data_setup_post_train, custom_data_setup_main_train\n",
    "from going_modular.ThreeHeadCNN import ThreeHeadCNN\n",
    "import helper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e5318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allow_train = False\n",
    "load_main_train_model = False\n",
    "freeze_encoder = False\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "shrink_size = None\n",
    "\n",
    "p = 0.3 # probability for augmentation\n",
    "lr = 0.001\n",
    "weight_deacay = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7082c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84a5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = helper_functions.get_augmentation_train_transforms(p)\n",
    "test_transforms = helper_functions.get_augmentation_test_transforms(p)\n",
    "no_transforms = helper_functions.get_augmentation_no_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fdaf5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all dataloaders\n",
    "\n",
    "train_dataloader, class_names = custom_data_setup_main_train.create_train_dataloader(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_transform=train_transforms,\n",
    "    shrink_size=shrink_size)\n",
    "\n",
    "test_dataloader, class_names = custom_data_setup_main_train.create_test_dataloader(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    test_transform=test_transforms, \n",
    "    shrink_size=shrink_size) \n",
    "\n",
    "exp_dataloader, class_names = custom_data_setup_main_train.create_train_dataloader(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_transform=train_transforms,\n",
    "    shrink_size=shrink_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9bbb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeHeadCNN(device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c9f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
    "if freeze_encoder:\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "if load_main_train_model:\n",
    "    model.load_state_dict(torch.load(\"models/main_train_model.pth\", weights_only=True, map_location=device))     \n",
    "\n",
    "with torch.no_grad():\n",
    "    model.final_head[0].weight.fill_(1/3)\n",
    "    model.final_head[0].bias.zero_()                  \n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False \n",
    "\n",
    "for param in model.final_head.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c1071c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "\n",
    "loss_fn = nn.MSELoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_deacay)\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f40587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "ThreeHeadCNN (ThreeHeadCNN)                                  [32, 3, 240, 240]    [32, 5]              --                   Partial\n",
       "├─Sequential (encoder)                                       [32, 3, 240, 240]    [32, 1792, 8, 8]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 240, 240]    [32, 48, 120, 120]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 240, 240]    [32, 48, 120, 120]   (1,296)              False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 48, 120, 120]   [32, 48, 120, 120]   (96)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 48, 120, 120]   [32, 48, 120, 120]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 48, 120, 120]   [32, 24, 120, 120]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 48, 120, 120]   [32, 24, 120, 120]   (2,940)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 120, 120]   [32, 24, 120, 120]   (1,206)              False\n",
       "│    └─Sequential (2)                                        [32, 24, 120, 120]   [32, 32, 60, 60]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 120, 120]   [32, 32, 60, 60]     (11,878)             False\n",
       "│    │    └─MBConv (1)                                       [32, 32, 60, 60]     [32, 32, 60, 60]     (18,120)             False\n",
       "│    │    └─MBConv (2)                                       [32, 32, 60, 60]     [32, 32, 60, 60]     (18,120)             False\n",
       "│    │    └─MBConv (3)                                       [32, 32, 60, 60]     [32, 32, 60, 60]     (18,120)             False\n",
       "│    └─Sequential (3)                                        [32, 32, 60, 60]     [32, 56, 30, 30]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 60, 60]     [32, 56, 30, 30]     (25,848)             False\n",
       "│    │    └─MBConv (1)                                       [32, 56, 30, 30]     [32, 56, 30, 30]     (57,246)             False\n",
       "│    │    └─MBConv (2)                                       [32, 56, 30, 30]     [32, 56, 30, 30]     (57,246)             False\n",
       "│    │    └─MBConv (3)                                       [32, 56, 30, 30]     [32, 56, 30, 30]     (57,246)             False\n",
       "│    └─Sequential (4)                                        [32, 56, 30, 30]     [32, 112, 15, 15]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 56, 30, 30]     [32, 112, 15, 15]    (70,798)             False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 15, 15]    [32, 112, 15, 15]    (197,820)            False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 15, 15]    [32, 112, 15, 15]    (197,820)            False\n",
       "│    │    └─MBConv (3)                                       [32, 112, 15, 15]    [32, 112, 15, 15]    (197,820)            False\n",
       "│    │    └─MBConv (4)                                       [32, 112, 15, 15]    [32, 112, 15, 15]    (197,820)            False\n",
       "│    │    └─MBConv (5)                                       [32, 112, 15, 15]    [32, 112, 15, 15]    (197,820)            False\n",
       "│    └─Sequential (5)                                        [32, 112, 15, 15]    [32, 160, 15, 15]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 15, 15]    [32, 160, 15, 15]    (240,924)            False\n",
       "│    │    └─MBConv (1)                                       [32, 160, 15, 15]    [32, 160, 15, 15]    (413,160)            False\n",
       "│    │    └─MBConv (2)                                       [32, 160, 15, 15]    [32, 160, 15, 15]    (413,160)            False\n",
       "│    │    └─MBConv (3)                                       [32, 160, 15, 15]    [32, 160, 15, 15]    (413,160)            False\n",
       "│    │    └─MBConv (4)                                       [32, 160, 15, 15]    [32, 160, 15, 15]    (413,160)            False\n",
       "│    │    └─MBConv (5)                                       [32, 160, 15, 15]    [32, 160, 15, 15]    (413,160)            False\n",
       "│    └─Sequential (6)                                        [32, 160, 15, 15]    [32, 272, 8, 8]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 160, 15, 15]    [32, 272, 8, 8]      (520,904)            False\n",
       "│    │    └─MBConv (1)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      (1,159,332)          False\n",
       "│    │    └─MBConv (2)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      (1,159,332)          False\n",
       "│    │    └─MBConv (3)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      (1,159,332)          False\n",
       "│    │    └─MBConv (4)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      (1,159,332)          False\n",
       "│    │    └─MBConv (5)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      (1,159,332)          False\n",
       "│    │    └─MBConv (6)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      (1,159,332)          False\n",
       "│    │    └─MBConv (7)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      (1,159,332)          False\n",
       "│    └─Sequential (7)                                        [32, 272, 8, 8]      [32, 448, 8, 8]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 272, 8, 8]      [32, 448, 8, 8]      (1,420,804)          False\n",
       "│    │    └─MBConv (1)                                       [32, 448, 8, 8]      [32, 448, 8, 8]      (3,049,200)          False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 448, 8, 8]      [32, 1792, 8, 8]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 448, 8, 8]      [32, 1792, 8, 8]     (802,816)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1792, 8, 8]     [32, 1792, 8, 8]     (3,584)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1792, 8, 8]     [32, 1792, 8, 8]     --                   --\n",
       "├─AdaptiveMaxPool2d (global_max_pool)                        [32, 1792, 8, 8]     [32, 1792, 1, 1]     --                   --\n",
       "├─AdaptiveAvgPool2d (global_avg_pool)                        [32, 1792, 8, 8]     [32, 1792, 1, 1]     --                   --\n",
       "├─BatchNorm1d (batch_norm_1)                                 [32, 1792]           [32, 1792]           (3,584)              False\n",
       "├─BatchNorm1d (batch_norm_2)                                 [32, 1792]           [32, 1792]           (3,584)              False\n",
       "├─Linear (dense1)                                            [32, 3584]           [32, 1024]           (3,671,040)          False\n",
       "├─Sequential (classification_head)                           [32, 1024]           [32, 5]              --                   False\n",
       "│    └─Linear (0)                                            [32, 1024]           [32, 128]            (131,200)            False\n",
       "│    └─ReLU (1)                                              [32, 128]            [32, 128]            --                   --\n",
       "│    └─Dropout (2)                                           [32, 128]            [32, 128]            --                   --\n",
       "│    └─Linear (3)                                            [32, 128]            [32, 5]              (645)                False\n",
       "├─Sequential (regression_head)                               [32, 1024]           [32, 1]              --                   False\n",
       "│    └─Linear (0)                                            [32, 1024]           [32, 128]            (131,200)            False\n",
       "│    └─ReLU (1)                                              [32, 128]            [32, 128]            --                   --\n",
       "│    └─Dropout (2)                                           [32, 128]            [32, 128]            --                   --\n",
       "│    └─Linear (3)                                            [32, 128]            [32, 1]              (129)                False\n",
       "├─Sequential (ordinal_head)                                  [32, 1024]           [32, 5]              --                   False\n",
       "│    └─Linear (0)                                            [32, 1024]           [32, 128]            (131,200)            False\n",
       "│    └─ReLU (1)                                              [32, 128]            [32, 128]            --                   --\n",
       "│    └─Dropout (2)                                           [32, 128]            [32, 128]            --                   --\n",
       "│    └─Linear (3)                                            [32, 128]            [32, 5]              (645)                False\n",
       "├─Sequential (final_head)                                    [32, 3]              [32, 1]              --                   True\n",
       "│    └─Linear (0)                                            [32, 3]              [32, 1]              4                    True\n",
       "============================================================================================================================================\n",
       "Total params: 21,621,847\n",
       "Trainable params: 4\n",
       "Non-trainable params: 21,621,843\n",
       "Total mult-adds (G): 58.07\n",
       "============================================================================================================================================\n",
       "Input size (MB): 22.12\n",
       "Forward/backward pass size (MB): 10157.97\n",
       "Params size (MB): 86.49\n",
       "Estimated Total Size (MB): 10266.58\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a summary using torchinfo (uncomment for actual output)\n",
    "torch.manual_seed(33)\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 240, 240), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "585ba3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = []\n",
    "\n",
    "if allow_train:\n",
    "    # Set the random seeds\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "    # Start the timer\n",
    "    from timeit import default_timer as timer \n",
    "    start_time = timer()\n",
    "\n",
    "    # Setup training and save the results\n",
    "    train_results = engine_post_train.train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=EPOCHS,\n",
    "        device=device)\n",
    "        \n",
    "    # End the timer and print out how long it took\n",
    "    end_time = timer()\n",
    "    print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
    "\n",
    "    utils.save_model(model=model, target_dir='models', model_name='post_train_model.pth')\n",
    "else:\n",
    "    model.load_state_dict(torch.load('models/post_train_model.pth', weights_only=True, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae15bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if allow_train:\n",
    "    helper_functions.plot_loss_curves_post_train(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6073a35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_per_class: tensor([0.9291, 0.4429, 0.6160, 0.3023, 0.5124])\n",
      "f1_score_macro (unweighted average): 0.56052565574646\n",
      "test acc: 0.7393229166666667\n",
      "QWK score: 0.8773276209831238\n"
     ]
    }
   ],
   "source": [
    "test_results = engine_post_train.test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99f1c2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_per_class: tensor([0.9277, 0.4612, 0.7152, 0.3770, 0.4839])\n",
      "f1_score_macro (unweighted average): 0.5929898023605347\n",
      "test acc: 0.7581925675675676\n",
      "QWK score: 0.8871617913246155\n"
     ]
    }
   ],
   "source": [
    "test_results = engine_post_train.test_step(model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvMasoudi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
