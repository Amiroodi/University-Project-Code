{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e5318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allow_train = True\n",
    "freeze_encoder = False\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "shrink_size = 200\n",
    "\n",
    "lr = 0.5\n",
    "weight_deacay = 1e-4\n",
    "T_max = 5\n",
    "eta_min = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cea12766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from going_modular import engine_post_train, utils\n",
    "from going_modular import custom_data_setup_post_train\n",
    "import helper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a7082c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c84a5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_transforms = helper_functions.get_augmentation_no_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fdaf5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\University Project\\University-Project-Code\\University-Project-Code\\going_modular\\custom_data_setup_post_train.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"models/main_train_model.pth\", map_location=device))\n",
      "d:\\University Project\\University-Project-Code\\University-Project-Code\\going_modular\\custom_data_setup_post_train.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"models/main_train_model.pth\", map_location=device))\n",
      "d:\\University Project\\University-Project-Code\\University-Project-Code\\going_modular\\custom_data_setup_post_train.py:111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"models/main_train_model.pth\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "train_val_dataloader, class_names = custom_data_setup_post_train.create_train_val_dataloader(transform=no_transforms, batch_size=BATCH_SIZE, device=device, shrink_size=shrink_size)\n",
    "\n",
    "test_dataloader, class_names = custom_data_setup_post_train.create_test_dataloader(transform=no_transforms, batch_size=BATCH_SIZE, device=device, shrink_size=shrink_size)\n",
    "\n",
    "exp_dataloader, class_names = custom_data_setup_post_train.create_train_dataloader(transform=no_transforms, batch_size=BATCH_SIZE, device=device, shrink_size=shrink_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00b7e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHeadCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneHeadCNN, self).__init__()\n",
    "        self.final_head = nn.Linear(3, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.final_head(x)\n",
    "\n",
    "model = OneHeadCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c794f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHeadCNN(\n",
       "  (final_head): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize all weights to 1/3\n",
    "def init_weights_custom(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.constant_(m.weight, 1/3)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "model.apply(init_weights_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c1071c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "\n",
    "loss_fn = nn.MSELoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=weight_deacay)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "585ba3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2a618bf8b742149324a09d9f3c42aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "loss_train: 2.0187 | loss_val: 1.5594 | acc_val: 0.5156\n",
      "\n",
      "Epoch: 2\n",
      "loss_train: 1.7746 | loss_val: 1.8558 | acc_val: 0.5000\n",
      "\n",
      "Epoch: 3\n",
      "loss_train: 1.6707 | loss_val: 1.2535 | acc_val: 0.4844\n",
      "\n",
      "Epoch: 4\n",
      "loss_train: 1.6685 | loss_val: 1.4349 | acc_val: 0.2500\n",
      "\n",
      "Epoch: 5\n",
      "loss_train: 1.7171 | loss_val: 1.4571 | acc_val: 0.2656\n",
      "\n",
      "Epoch: 6\n",
      "loss_train: 1.7067 | loss_val: 1.3039 | acc_val: 0.4375\n",
      "\n",
      "Epoch: 7\n",
      "loss_train: 1.6575 | loss_val: 1.3272 | acc_val: 0.4062\n",
      "\n",
      "Epoch: 8\n",
      "loss_train: 1.6672 | loss_val: 1.3950 | acc_val: 0.3594\n",
      "\n",
      "Epoch: 9\n",
      "loss_train: 1.7051 | loss_val: 1.2726 | acc_val: 0.2031\n",
      "\n",
      "Epoch: 10\n",
      "loss_train: 1.6750 | loss_val: 1.3362 | acc_val: 0.5156\n",
      "\n",
      "Epoch: 11\n",
      "loss_train: 1.6695 | loss_val: 1.3558 | acc_val: 0.4531\n",
      "\n",
      "Epoch: 12\n",
      "loss_train: 1.6766 | loss_val: 1.9306 | acc_val: 0.3594\n",
      "\n",
      "Epoch: 13\n",
      "loss_train: 1.6420 | loss_val: 1.4015 | acc_val: 0.2500\n",
      "\n",
      "Epoch: 14\n",
      "loss_train: 1.6476 | loss_val: 1.8538 | acc_val: 0.3594\n",
      "\n",
      "Epoch: 15\n",
      "loss_train: 1.7436 | loss_val: 1.8277 | acc_val: 0.4062\n",
      "\n",
      "Epoch: 16\n",
      "loss_train: 1.7417 | loss_val: 1.6369 | acc_val: 0.5156\n",
      "\n",
      "Epoch: 17\n",
      "loss_train: 1.8367 | loss_val: 1.4407 | acc_val: 0.1875\n",
      "\n",
      "Epoch: 18\n",
      "loss_train: 1.8447 | loss_val: 1.2663 | acc_val: 0.4688\n",
      "\n",
      "Epoch: 19\n",
      "loss_train: 1.6993 | loss_val: 1.4717 | acc_val: 0.5469\n",
      "\n",
      "Epoch: 20\n",
      "loss_train: 1.7099 | loss_val: 1.5834 | acc_val: 0.2031\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542bae57a891407691b5ae1b8227d8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "loss_train: 1.7620 | loss_val: 1.7921 | acc_val: 0.1562\n",
      "\n",
      "Epoch: 2\n",
      "loss_train: 1.7776 | loss_val: 1.8374 | acc_val: 0.2188\n",
      "\n",
      "Epoch: 3\n",
      "loss_train: 1.7263 | loss_val: 1.6884 | acc_val: 0.2344\n",
      "\n",
      "Epoch: 4\n",
      "loss_train: 1.7134 | loss_val: 1.3832 | acc_val: 0.2656\n",
      "\n",
      "Epoch: 5\n",
      "loss_train: 1.6412 | loss_val: 1.3919 | acc_val: 0.1719\n",
      "\n",
      "Epoch: 6\n",
      "loss_train: 1.6495 | loss_val: 1.7922 | acc_val: 0.1250\n",
      "\n",
      "Epoch: 7\n",
      "loss_train: 1.6716 | loss_val: 1.5039 | acc_val: 0.2656\n",
      "\n",
      "Epoch: 8\n",
      "loss_train: 1.6584 | loss_val: 2.0221 | acc_val: 0.1562\n",
      "\n",
      "Epoch: 9\n",
      "loss_train: 1.9262 | loss_val: 2.2311 | acc_val: 0.2031\n",
      "\n",
      "Epoch: 10\n",
      "loss_train: 1.7751 | loss_val: 1.6295 | acc_val: 0.2656\n",
      "\n",
      "Epoch: 11\n",
      "loss_train: 2.0157 | loss_val: 2.6750 | acc_val: 0.1094\n",
      "\n",
      "Epoch: 12\n",
      "loss_train: 2.0367 | loss_val: 1.6103 | acc_val: 0.2188\n",
      "\n",
      "Epoch: 13\n",
      "loss_train: 2.0922 | loss_val: 2.4235 | acc_val: 0.3594\n",
      "\n",
      "Epoch: 14\n",
      "loss_train: 2.2302 | loss_val: 1.5456 | acc_val: 0.1719\n",
      "\n",
      "Epoch: 15\n",
      "loss_train: 1.8199 | loss_val: 2.2335 | acc_val: 0.1875\n",
      "\n",
      "Epoch: 16\n",
      "loss_train: 1.8362 | loss_val: 2.0938 | acc_val: 0.1719\n",
      "\n",
      "Epoch: 17\n",
      "loss_train: 1.8326 | loss_val: 1.9120 | acc_val: 0.3125\n",
      "\n",
      "Epoch: 18\n",
      "loss_train: 1.7694 | loss_val: 2.3090 | acc_val: 0.2188\n",
      "\n",
      "Epoch: 19\n",
      "loss_train: 2.0288 | loss_val: 2.2152 | acc_val: 0.0469\n",
      "\n",
      "Epoch: 20\n",
      "loss_train: 2.0504 | loss_val: 1.4629 | acc_val: 0.2500\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b7af06444a460c876c4e9f76ce8092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "loss_train: 2.0308 | loss_val: 2.0309 | acc_val: 0.2656\n",
      "\n",
      "Epoch: 2\n",
      "loss_train: 2.1615 | loss_val: 1.4656 | acc_val: 0.2344\n",
      "\n",
      "Epoch: 3\n",
      "loss_train: 1.9052 | loss_val: 1.9320 | acc_val: 0.1875\n",
      "\n",
      "Epoch: 4\n",
      "loss_train: 2.0045 | loss_val: 1.6526 | acc_val: 0.2031\n",
      "\n",
      "Epoch: 5\n",
      "loss_train: 1.7352 | loss_val: 1.8526 | acc_val: 0.2344\n",
      "\n",
      "Epoch: 6\n",
      "loss_train: 1.7587 | loss_val: 1.7355 | acc_val: 0.1719\n",
      "\n",
      "Epoch: 7\n",
      "loss_train: 1.8898 | loss_val: 1.9692 | acc_val: 0.1094\n",
      "\n",
      "Epoch: 8\n",
      "loss_train: 1.8475 | loss_val: 1.4403 | acc_val: 0.2188\n",
      "\n",
      "Epoch: 9\n",
      "loss_train: 1.9265 | loss_val: 1.3779 | acc_val: 0.2812\n",
      "\n",
      "Epoch: 10\n",
      "loss_train: 1.7514 | loss_val: 2.2655 | acc_val: 0.1250\n",
      "\n",
      "Epoch: 11\n",
      "loss_train: 2.6030 | loss_val: 2.8494 | acc_val: 0.0000\n",
      "\n",
      "Epoch: 12\n",
      "loss_train: 2.6808 | loss_val: 1.8923 | acc_val: 0.1406\n",
      "\n",
      "Epoch: 13\n",
      "loss_train: 1.9944 | loss_val: 1.6423 | acc_val: 0.4062\n",
      "\n",
      "Epoch: 14\n",
      "loss_train: 2.2128 | loss_val: 1.5572 | acc_val: 0.1562\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Setup training and save the results\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m train_val_dataloader:\n\u001b[1;32m---> 18\u001b[0m     train_results, val_results \u001b[38;5;241m=\u001b[39m \u001b[43mengine_post_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_dataloader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_dataloader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     folds_train_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_train\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(train_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_train\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     29\u001b[0m     folds_val_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_val\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(val_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_val\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32md:\\University Project\\University-Project-Code\\University-Project-Code\\going_modular\\engine_post_train.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, val_dataloader, optimizer, scheduler, loss_fn, epochs, device)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Loop through training and testing steps for a number of epochs\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m--> 185\u001b[0m     loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m                           \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     loss_val, acc_val \u001b[38;5;241m=\u001b[39m val_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    193\u001b[0m                               dataloader\u001b[38;5;241m=\u001b[39mval_dataloader,\n\u001b[0;32m    194\u001b[0m                               loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[0;32m    195\u001b[0m                               device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# Print out what's happening\u001b[39;00m\n",
      "File \u001b[1;32md:\\University Project\\University-Project-Code\\University-Project-Code\\going_modular\\engine_post_train.py:28\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, dataloader, loss_fn, optimizer, scheduler, device)\u001b[0m\n\u001b[0;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Loop through data loader data batches\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Send data to target device\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print('X is: ', X)\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print('y float is: ', y.float())\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# out looks like this: tensor([a, b, c, d])\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:896\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    893\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    894\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 896\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:828\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    826\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 828\u001b[0m     res \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWaitForMultipleObjects(L, \u001b[38;5;28;01mFalse\u001b[39;00m, timeout)\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    830\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folds_train_results = {\n",
    "    'loss_train': []\n",
    "}\n",
    "folds_val_results = {\n",
    "    'loss_val': []\n",
    "}\n",
    "if allow_train:\n",
    "    # Set the random seeds\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "    # Start the timer\n",
    "    from timeit import default_timer as timer \n",
    "    start_time = timer()\n",
    "\n",
    "    # Setup training and save the results\n",
    "    for fold in train_val_dataloader:\n",
    "        train_results, val_results = engine_post_train.train(model=model,\n",
    "                            train_dataloader=fold['train_dataloader'],\n",
    "                            val_dataloader=fold['val_dataloader'],\n",
    "                            optimizer=optimizer,\n",
    "                            scheduler=scheduler,\n",
    "                            loss_fn=loss_fn,\n",
    "                            epochs=EPOCHS,\n",
    "                            device=device)\n",
    "        \n",
    "        folds_train_results['loss_train'].extend(train_results['loss_train'])\n",
    "\n",
    "        folds_val_results['loss_val'].extend(val_results['loss_val'])\n",
    "\n",
    "    # End the timer and print out how long it took\n",
    "    end_time = timer()\n",
    "    print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
    "\n",
    "    utils.save_model(model=model, target_dir='models', model_name='post_train_model.pth')\n",
    "else:\n",
    "    model.load_state_dict(torch.load('models/post_train_model.pth', weights_only=True, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae15bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if allow_train:\n",
    "    helper_functions.plot_loss_curves_post_train(folds_train_results, folds_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6073a35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.25\n"
     ]
    }
   ],
   "source": [
    "test_results = engine_post_train.test_step(\n",
    "    model=model,\n",
    "    dataloader=exp_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
